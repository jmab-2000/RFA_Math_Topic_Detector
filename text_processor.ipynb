{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bac9d5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(min_df=0,\n",
      "                stop_words=['(l)', '(polynomial)', '(w)',\n",
      "                            'add(mul(integer((d))pow(symbol(x)integer((d))))symbol(x)mul(integer(-(d))mul(integer((d))integer((d))pow(mul(integer((d))symbol(x))mul(integer((d))pow(integer((d))integer(-(d))))))))',\n",
      "                            'add(mul(integer(-(d))integer((d))pow(integer((d))mul(integer((d))pow(integer((d))integer(-(d))))))in...\n",
      "                            'add(symbol(x)mul(integer(-(d))mul(integer((d))integer((d))symbol(x))))',\n",
      "                            'add(symbol(x)symbol(x))', 'advised', 'allowance',\n",
      "                            'answered', 'any)', 'asked', 'bank', 'blank', 'box',\n",
      "                            'buy', 'cardboard', 'centimeter', 'centimeters',\n",
      "                            'chain', 'christmas', 'classmate', 'classroom',\n",
      "                            'closely', 'cm', 'composed', 'consider', 'constant',\n",
      "                            'construction', 'contains', ...],\n",
      "                token_pattern='[a-zA-Z0-9,=+-<>()_{}]+')\n"
     ]
    }
   ],
   "source": [
    "# to be added on views.py\n",
    "\n",
    "import pickle\n",
    "\n",
    "loaded_model = pickle.load(open('rfa_model.sav', 'rb'))\n",
    "loaded_model\n",
    "\n",
    "extractor = pickle.load(open('vectorizer.sav', 'rb'))\n",
    "print(extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8074fa71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Removing Equal Sign Inside LaTex So That Sympy would not evaluate the equation or answer the equation\n",
      "it is an ordered set of pattern or rule (a1, a2,...)\n",
      "Step 2: Converting LaTex Expressions into Freeform Structure\n",
      "it is an ordered set of pattern or rule (a1, a2,...)\n",
      "Step 3: Removing Unnecessary Characters\n",
      "it is an ordered set of pattern or rule (a1 a2)\n",
      "(a1\n",
      "(a1\n",
      "a2)\n",
      "a2)\n",
      "Step 4: Expressing Freeform Equations into Expression trees\n",
      "it is an ordered set of pattern or rule (a(d) a(d))\n",
      "Step 5: vectorizing the question based on the dataset\n",
      "  (0, 506)\t1\n",
      "  (0, 511)\t1\n",
      "  (0, 539)\t1\n",
      "Step 6: Classifying the question\n",
      "['series_and_sequence']\n"
     ]
    }
   ],
   "source": [
    "# To be added on views.py on webapp\n",
    "\n",
    "\n",
    "from latex2sympy2 import latex2sympy\n",
    "from sympy import *\n",
    "from sympy.parsing.sympy_parser import parse_expr\n",
    "import re\n",
    "\n",
    "\n",
    "#Changes Before Sympy\n",
    "def change_to_dollar(exp):\n",
    "    exp = re.sub(\"\\.\\.\\.|\\\\dots|â€¦\",\"x\", exp)\n",
    "    exp = re.sub(\"=\",\"$ $\", exp)\n",
    "    return exp\n",
    "\n",
    "def expression_checker(question):\n",
    "    qs = question\n",
    "    qs = re.sub(r\"\\\\sqrt\\{(.+?)\\}\", r\"(\\1)^{\\\\frac{1}{2}}\", qs)\n",
    "    qs = re.sub(r\"[\\\\][(][)][\\\\]\", \"$\", qs)\n",
    "    fx = re.search('[$].+?[=].+?[$]',qs)\n",
    "    len_check = len(re.findall('[$].+?[=].+?[$]', qs))\n",
    "    iplus = 0\n",
    "    while iplus<len_check:\n",
    "        iplus += 1\n",
    "        qs = qs[:fx.span()[0]] + \" \" + change_to_dollar(fx.group()) + \" \" + qs[fx.span()[1]:]\n",
    "        #check for the next LaTex Enclosure if any         \n",
    "        fx = re.search('[$].+?[=].+?[$]', qs)\n",
    "    #the new question is added to index i       \n",
    "    return qs\n",
    "\n",
    "def sympify(question):\n",
    "    test = question\n",
    "    #regex value for searching all characters from '$' to the next '$' symbol\n",
    "    check = re.search('[$].+?[$]',test)\n",
    "    #checks how many instance of latex enclosure are there in the question     \n",
    "    check_len = len(re.findall('[$].+?[$]',test))\n",
    "    iteration = 0\n",
    "    while iteration<check_len:\n",
    "        iteration += 1\n",
    "        print(check.group())\n",
    "        test = test[:check.span()[0]] + \" \" + re.sub(\" \",\"\",str(latex2sympy(r\"{}\".format(check.group())))) + \" \" + test[check.span()[1]:]   \n",
    "        check = re.search('[$].+?[$]',test)       \n",
    "    return test\n",
    "\n",
    "# Change Must Happen After Sympy \n",
    "def change_characters(question):   \n",
    "    question = re.sub(' \\+ ', '+',question)\n",
    "    question = re.sub(' - ', '-',question)\n",
    "    question = re.sub(' \\+', '+',question)\n",
    "    question = re.sub(' -', '-',question)\n",
    "    question = re.sub('\\+ ', '+',question)\n",
    "    question = re.sub('- ', '-',question)\n",
    "    question = re.sub('=', ' ',question)\n",
    "    question = re.sub('\\n','',question)\n",
    "    question = re.sub('\\?','',question)\n",
    "    question = re.sub('\\'','',question)\n",
    "    question = re.sub(',','',question)\n",
    "    question = re.sub('[\\.]','',question)\n",
    "    question = re.sub('\\t', ' ',question)\n",
    "    question = re.sub(r\"\\_\\_+\", \"__\",question)\n",
    "    question = re.sub('[;]', ' ',question)\n",
    "    question = re.sub(':', ' ',question)\n",
    "    return question\n",
    "    \n",
    "\n",
    "def tokenize_formula(expression):\n",
    "    try:\n",
    "        return srepr(parse_expr(expression, evaluate=False))\n",
    "    except:\n",
    "        return expression\n",
    "\n",
    "def expression_treefy(question):\n",
    "    item_question = question\n",
    "    tokenize_question_item = item_question.split()\n",
    "    for x in range(len(tokenize_question_item)):\n",
    "        check = re.findall('[\\+]|[\\*]|[-]|[/]|[0-9]',tokenize_question_item[x])\n",
    "        if len(tokenize_question_item[x]) == 1:\n",
    "            check = True \n",
    "        if check: \n",
    "            print(tokenize_question_item[x])\n",
    "            text = re.sub(\"\\s|[,]\",\"\",str(tokenize_formula(tokenize_question_item[x])))\n",
    "            print(text)\n",
    "            text = re.sub(\"\\d+\",\"(d)\",text)\n",
    "            text = re.sub(\"[(]['].+?['][)]\",\"(x)\",text)\n",
    "#             text = re.sub(\"Symbol[(]['].+?['][)]\",\"symbol(x)\",text)\n",
    "            text = re.sub('\\s+', '', text)\n",
    "            tokenize_question_item[x] = text\n",
    "    item_question = ' '.join(tokenize_question_item)\n",
    "    return item_question\n",
    "\n",
    "\n",
    "# Token from Django have '\\(' '\\)' enclosures so that HTML can render LaTex Expression\n",
    "# We convert them to $$ enclosure because of old dataset that we have before mathquill was applied to the system\n",
    "# In this classify_topic function we did not include that function so we only evalue questions that are already enclosed by \n",
    "# $ $ sign\n",
    "\n",
    "def classify_topic(cleaned_question):\n",
    "    question = cleaned_question\n",
    "    question = expression_checker(question)\n",
    "    print(\"Step 1: Removing Equal Sign Inside LaTex So That Sympy would not evaluate the equation or answer the equation\")\n",
    "    print(question)\n",
    "    question = sympify(question)\n",
    "    print(\"Step 2: Converting LaTex Expressions into Freeform Structure\")\n",
    "    print(question)\n",
    "    question = change_characters(question)\n",
    "    print(\"Step 3: Removing Unnecessary Characters\")\n",
    "    print(question)\n",
    "    question = expression_treefy(question)\n",
    "    print(\"Step 4: Expressing Freeform Equations into Expression trees\")\n",
    "    print(question)\n",
    "    vector = extractor.transform([question])\n",
    "    print(\"Step 5: vectorizing the question based on the dataset\")\n",
    "    print(vector)\n",
    "    topic = loaded_model.predict(vector)\n",
    "    print(\"Step 6: Classifying the question\")\n",
    "    return topic\n",
    "\n",
    "# it is advised that equation written are in LaTex or Freeform structure\n",
    "\n",
    "test = r\"it is an ordered set of pattern or rule (a1, a2,...)\"\n",
    "topic = classify_topic(test)\n",
    "print(topic)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
